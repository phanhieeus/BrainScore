{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12038504,"sourceType":"datasetVersion","datasetId":7317087},{"sourceId":12048897,"sourceType":"datasetVersion","datasetId":7323829}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":22254.432332,"end_time":"2025-06-01T22:32:23.570725","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-01T16:21:29.138393","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03d2769fde4b47e380d973cdf9e80a70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05ee0761ff194b5d831ee382a1e1d0a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb64504d4e1649de933d7a88bf2f5509","placeholder":"​","style":"IPY_MODEL_ab129bcdaa2f47aaa96ad17e36cb0f14","value":"\n<b>Thank You</b></center>"}},"12abe82837de4bd9bb3bf080939b493a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19a0915dab2e41b9bfeb4f4f00623eea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d7bc82ebac4451f9fa155d528c2250a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2474a29c59044abda97fa0fafa54fd80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"262356e006ae43c7b733431fde17ef15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ec4b4fb4e064afd9eaf2ba291120e11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b695b361a4b34b87a25835b5af9b0586","placeholder":"​","style":"IPY_MODEL_03d2769fde4b47e380d973cdf9e80a70","value":"<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"}},"349d53a77e244ec088701bcfc99cc18b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d7bc82ebac4451f9fa155d528c2250a","placeholder":"​","style":"IPY_MODEL_262356e006ae43c7b733431fde17ef15","value":"Kaggle credentials successfully validated."}},"5015410ed96348b39e6a5b79cae07d25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"7e8d8c570f7a4e33bf3351af4137cafb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"TextModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Username:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_2474a29c59044abda97fa0fafa54fd80","placeholder":"​","style":"IPY_MODEL_d87a46fc65214f5aae742a428002b2b3","value":"ttn2807"}},"86b707412de54ffa85f69c78d7480571":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_349d53a77e244ec088701bcfc99cc18b"],"layout":"IPY_MODEL_5015410ed96348b39e6a5b79cae07d25"}},"a5c85673c8f547988844ab2fa8e4cc25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab129bcdaa2f47aaa96ad17e36cb0f14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac81cc5e40a84f66bdb5afb9daaa21a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_ed49021b9f8447a5b2af63c731cb600c","placeholder":"​","style":"IPY_MODEL_ccc1ea51b32a404583e408efebe68539","value":""}},"b695b361a4b34b87a25835b5af9b0586":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb64504d4e1649de933d7a88bf2f5509":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3aa2c7bf6fe441991e444bd0ad284d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19a0915dab2e41b9bfeb4f4f00623eea","placeholder":"​","style":"IPY_MODEL_12abe82837de4bd9bb3bf080939b493a","value":"Connecting..."}},"ccc1ea51b32a404583e408efebe68539":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d87a46fc65214f5aae742a428002b2b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db9b739f1ee0408b89e92a2b42ac4420":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"e3e5600c5d914fae93a2cb69462dd028":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_a5c85673c8f547988844ab2fa8e4cc25","style":"IPY_MODEL_db9b739f1ee0408b89e92a2b42ac4420","tooltip":""}},"ed49021b9f8447a5b2af63c731cb600c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{"id":"0TwAoYEuuWaR","papermill":{"duration":0.00833,"end_time":"2025-06-01T16:21:33.301956","exception":false,"start_time":"2025-06-01T16:21:33.293626","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install torchio","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:46:48.279089Z","iopub.execute_input":"2025-06-04T17:46:48.279381Z","iopub.status.idle":"2025-06-04T17:48:33.279660Z","shell.execute_reply.started":"2025-06-04T17:46:48.279352Z","shell.execute_reply":"2025-06-04T17:48:33.278281Z"},"id":"uR4BTOtjuWaS","outputId":"ff46a852-f2c4-4bb9-c98f-500d3b68e23c","papermill":{"duration":76.691388,"end_time":"2025-06-01T16:22:50.000262","exception":false,"start_time":"2025-06-01T16:21:33.308874","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Collecting torchio\n  Downloading torchio-0.20.8-py3-none-any.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.11/dist-packages (from torchio) (1.2.18)\nRequirement already satisfied: einops>=0.3 in /usr/local/lib/python3.11/dist-packages (from torchio) (0.8.1)\nRequirement already satisfied: humanize>=0.1 in /usr/local/lib/python3.11/dist-packages (from torchio) (4.12.2)\nRequirement already satisfied: nibabel>=3 in /usr/local/lib/python3.11/dist-packages (from torchio) (5.3.2)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from torchio) (1.26.4)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from torchio) (25.0)\nRequirement already satisfied: rich>=10 in /usr/local/lib/python3.11/dist-packages (from torchio) (14.0.0)\nRequirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.11/dist-packages (from torchio) (1.15.2)\nRequirement already satisfied: simpleitk!=2.0.*,!=2.1.1.1,>=1.3 in /usr/local/lib/python3.11/dist-packages (from torchio) (2.5.0)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from torchio) (2.6.0+cu124)\nRequirement already satisfied: tqdm>=4.40 in /usr/local/lib/python3.11/dist-packages (from torchio) (4.67.1)\nRequirement already satisfied: typer>=0.1 in /usr/local/lib/python3.11/dist-packages (from torchio) (0.15.2)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2->torchio) (1.17.2)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel>=3->torchio) (6.5.2)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel>=3->torchio) (4.13.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->torchio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->torchio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->torchio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->torchio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->torchio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->torchio) (2.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10->torchio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10->torchio) (2.19.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->torchio)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->torchio)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->torchio)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->torchio)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->torchio)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->torchio)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->torchio)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->torchio) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->torchio) (1.3.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.1->torchio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.1->torchio) (1.5.4)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10->torchio) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->torchio) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->torchio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->torchio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->torchio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->torchio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->torchio) (2024.2.0)\nDownloading torchio-0.20.8-py3-none-any.whl (177 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchio\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchio-0.20.8\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport nibabel as nib\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.video import r3d_18\nfrom sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\nimport math\n\nfrom tqdm import tqdm\n\nimport torchio as T\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-06-04T17:48:33.282998Z","iopub.execute_input":"2025-06-04T17:48:33.283344Z","iopub.status.idle":"2025-06-04T17:48:46.252449Z","shell.execute_reply.started":"2025-06-04T17:48:33.283301Z","shell.execute_reply":"2025-06-04T17:48:46.251613Z"},"id":"TSOy1948uWaS","papermill":{"duration":14.030159,"end_time":"2025-06-01T16:23:04.059425","exception":false,"start_time":"2025-06-01T16:22:50.029266","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)                   # PyTorch CPU\n    torch.cuda.manual_seed(seed)              # PyTorch GPU (1 GPU)\n    torch.cuda.manual_seed_all(seed)          # PyTorch GPU (all GPUs)\n    torch.backends.cudnn.deterministic = True # CUDNN deterministic\n    torch.backends.cudnn.benchmark = False    # Turn off speed autotune\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.253360Z","iopub.execute_input":"2025-06-04T17:48:46.253797Z","iopub.status.idle":"2025-06-04T17:48:46.267603Z","shell.execute_reply.started":"2025-06-04T17:48:46.253772Z","shell.execute_reply":"2025-06-04T17:48:46.266314Z"},"papermill":{"duration":0.039614,"end_time":"2025-06-01T16:23:04.127940","exception":false,"start_time":"2025-06-01T16:23:04.088326","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load dataset","metadata":{"id":"kDuEoGA9uWaT","papermill":{"duration":0.028321,"end_time":"2025-06-01T16:23:04.184890","exception":false,"start_time":"2025-06-01T16:23:04.156569","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class AlzheimerDataset(Dataset):\n    def __init__(self, \n                 image_folder,\n                 data_csv,\n                 transform=None):\n        \"\"\"\n        Args:\n            image_folder: Path to folder containing image_id subfolders\n            data_csv: Path to CSV file containing all data (demographics, cognitive scores, follow-up)\n            transform: Optional transforms for MRI images\n        \"\"\"\n        \n        self.image_folder = image_folder\n        self.transform = transform\n        \n        # Load CSV file\n        self.data_df = pd.read_csv(data_csv)\n        \n        # Process data\n        self.data_df = self._process_data()\n        \n        # Filter valid samples (has image file and all required data)\n        self.valid_samples = self._filter_valid_samples()\n        \n    def _process_data(self):\n        \"\"\"Process the data from CSV file\"\"\"\n        df = self.data_df.copy()\n        \n        # Convert gender to numeric\n        df['PTGENDER'] = df['PTGENDER'].astype(np.float32)\n                \n        return df\n    \n    def _filter_valid_samples(self):\n        \"\"\"Filter samples that have valid image files and complete data\"\"\"\n        valid_samples = []\n        \n        # Check if image folder exists\n        if not os.path.exists(self.image_folder):\n            return valid_samples\n        \n        for idx, row in self.data_df.iterrows():                \n            image_id = row['image_id']\n            \n            # Construct folder path with \"I\" prefix\n            folder_name = f\"I{image_id}\"\n            image_path = os.path.join(self.image_folder, folder_name)\n            \n            if not os.path.exists(image_path):\n                continue\n            \n            # Look for the specific file name: T1_biascorr_brain.nii.gz\n            nii_file_path = os.path.join(image_path, \"T1_biascorr_brain.nii.gz\")\n            \n            if not os.path.exists(nii_file_path):\n                # If specific file doesn't exist, look for any .nii or .nii.gz file\n                if os.path.exists(image_path):\n                    files_in_folder = os.listdir(image_path)\n                    nii_files = [f for f in files_in_folder \n                                if f.endswith('.nii') or f.endswith('.nii.gz')]\n                    if len(nii_files) == 0:\n                        continue\n                    nii_file_path = os.path.join(image_path, nii_files[0])\n            \n            # Check for required data completeness\n            required_cols = [\n                'PTGENDER', 'age', 'PTEDUCAT', 'time_lapsed', 'DIAGNOSIS_now',\n                'ADAS11_now', 'ADAS13_now', 'MMSCORE_now',\n                'ADAS11_future', 'ADAS13_future', 'MMSCORE_future'\n            ]\n            missing_cols = [col for col in required_cols if col not in row or pd.isna(row[col])]\n            \n            if missing_cols:\n                continue\n            \n            # Store file path and index\n            valid_samples.append({\n                'idx': idx,\n                'image_path': nii_file_path,\n                'image_id': image_id\n            })\n        \n        return valid_samples\n    \n    def _load_mri_image(self, image_path):\n        \"\"\"Load and preprocess MRI image\"\"\"\n        # Load nii file\n        img = nib.load(image_path)\n        data = img.get_fdata()\n        \n        # Convert to float32 and add channel dimension\n        data = data.astype(np.float32)\n        \n        # Normalize intensity to [0, 1]\n        data = (data - data.min()) / (data.max() - data.min() + 1e-8)\n        \n        # Convert to tensor: (D, H, W)\n        data_tensor = torch.from_numpy(data)\n        \n        # Repeat single channel to create 3 channels: (3, D, H, W)\n        data_tensor = data_tensor.unsqueeze(0).repeat(3, 1, 1, 1)\n        \n        # Apply transforms if provided\n        if self.transform:\n            data_tensor = self.transform(data_tensor)\n        \n        return data_tensor\n    \n    def __len__(self):\n        return len(self.valid_samples)\n    \n    def __getitem__(self, idx):\n        # Get sample info\n        sample_info = self.valid_samples[idx]\n        df_idx = sample_info['idx']\n        image_path = sample_info['image_path']\n        \n        # Get row data\n        row = self.data_df.iloc[df_idx]\n        \n        # Load MRI image\n        mri_image = self._load_mri_image(image_path)\n\n        # Get demographics\n        demographics = torch.tensor([\n            row['age'],\n            row['PTGENDER'],\n            row['PTEDUCAT'],\n            row['DIAGNOSIS_now'],\n            row['ADAS11_now'],\n            row['ADAS13_now'],\n            row['MMSCORE_now'],\n            row['time_lapsed']\n        ], dtype=torch.float32)\n        \n        # Get cognitive scores\n        scores = {\n            'ADAS11_future': row['ADAS11_future'],\n            'ADAS13_future': row['ADAS13_future'],\n            'MMSCORE_future': row['MMSCORE_future']\n        }\n        \n        # Convert to tensors\n        targets = {\n            'adas11_future': torch.tensor(scores['ADAS11_future'], dtype=torch.float32),\n            'adas13_future': torch.tensor(scores['ADAS13_future'], dtype=torch.float32),\n            'mmscore_future': torch.tensor(scores['MMSCORE_future'], dtype=torch.float32)\n        }\n        \n        return mri_image, demographics, targets\n\n# Data loading utilities\ndef create_data_transforms(train=True, image_size=(64, 64, 64)):\n    \"\"\"Create transforms for MRI data\"\"\"\n    \n    if train:\n        transform = T.Compose([\n            T.Resize(image_size),\n            T.RandomFlip(axes=('LR',), p=0.5),\n            T.RandomAffine(scales=0.1, degrees=10, translation=5, p=0.75),\n            T.RandomNoise(std=0.01, p=0.5),\n            T.RandomMotion(p=0.3),\n            # T.ZNormalization()\n        ])\n    else:\n        transform = T.Compose([\n            T.Resize(image_size),\n            # T.ZNormalization()\n        ])\n    \n    return transform","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.268797Z","iopub.execute_input":"2025-06-04T17:48:46.269550Z","iopub.status.idle":"2025-06-04T17:48:46.290168Z","shell.execute_reply.started":"2025-06-04T17:48:46.269514Z","shell.execute_reply":"2025-06-04T17:48:46.289119Z"},"id":"5Zbw5vR5uWaT","papermill":{"duration":0.099112,"end_time":"2025-06-01T16:23:04.312231","exception":false,"start_time":"2025-06-01T16:23:04.213119","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def create_data_loaders(image_folder,\n                       train_data_csv,\n                       val_data_csv,\n                       test_data_csv,\n                       batch_size=8,\n                       image_size=(64, 64, 64)):\n    \"\"\"\n    Create train, validation, and test data loaders\n\n    Args:\n        image_folder: Path to MRI images folder\n        data_csv: Path to CSV file containing all data\n        batch_size: Batch size for training\n        image_size: Target size for MRI images\n\n    Returns:\n        train_loader, val_loader, test_loader\n    \"\"\"\n\n    # Create dataset\n    train_dataset = AlzheimerDataset(\n        image_folder=image_folder,\n        data_csv=train_data_csv,\n        transform=None  # Will be set later\n    )\n    val_dataset = AlzheimerDataset(\n        image_folder=image_folder,\n        data_csv=val_data_csv,\n        transform=None  # Will be set later\n    )\n    test_dataset = AlzheimerDataset(\n        image_folder=image_folder,\n        data_csv=test_data_csv,\n        transform=None  # Will be set later\n    )\n\n    # Create transforms\n    train_transform = create_data_transforms(train=True, image_size=image_size)\n    val_test_transform = create_data_transforms(train=False, image_size=image_size)\n\n    # Apply transforms\n    train_dataset.transform = train_transform\n    val_dataset.transform = val_test_transform\n    test_dataset.transform = val_test_transform\n\n    # Create data loaders\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True\n    )\n\n    val_loader = torch.utils.data.DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n\n    test_loader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n\n    print(f\"Data splits - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n\n    return train_loader, val_loader, test_loader\n\n# Example usage\ndef load_alzheimer_data(config):\n    \"\"\"\n    Load Alzheimer dataset with given configuration\n\n    config should contain:\n    - image_folder: path to images\n    - data_csv: path to data file\n    - batch_size: batch size\n    - image_size: tuple of target image dimensions\n    \"\"\"\n\n    train_loader, val_loader, test_loader = create_data_loaders(\n        image_folder=config['image_folder'],\n        train_data_csv=config['train_data_csv'],\n        val_data_csv=config['val_data_csv'],\n        test_data_csv=config['test_data_csv'],\n        batch_size=config.get('batch_size', 8),\n        image_size=config.get('image_size', (64, 64, 64))\n    )\n\n    return train_loader, val_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.291184Z","iopub.execute_input":"2025-06-04T17:48:46.291511Z","iopub.status.idle":"2025-06-04T17:48:46.312307Z","shell.execute_reply.started":"2025-06-04T17:48:46.291486Z","shell.execute_reply":"2025-06-04T17:48:46.311492Z"},"id":"vfu-WLstuWaU","papermill":{"duration":0.0383,"end_time":"2025-06-01T16:23:04.379839","exception":false,"start_time":"2025-06-01T16:23:04.341539","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Model","metadata":{"id":"Hc85rznRuWaV","papermill":{"duration":0.028581,"end_time":"2025-06-01T16:23:04.436882","exception":false,"start_time":"2025-06-01T16:23:04.408301","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# # 3D CNN backbone for MRI images - keep original pretrained weights\n# cnn_backbone = r3d_18(pretrained=True)\n# # Remove final classification layer\n# cnn_backbone.fc = nn.Identity()\n# for param in cnn_backbone.parameters():\n#     print(param.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.313338Z","iopub.execute_input":"2025-06-04T17:48:46.313676Z","iopub.status.idle":"2025-06-04T17:48:46.330685Z","shell.execute_reply.started":"2025-06-04T17:48:46.313646Z","shell.execute_reply":"2025-06-04T17:48:46.329711Z"},"papermill":{"duration":0.033691,"end_time":"2025-06-01T16:23:04.499121","exception":false,"start_time":"2025-06-01T16:23:04.465430","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class AlzheimerMultiTaskModel(nn.Module):\n    def __init__(self, pretrained=True, dropout_rate=0.5):\n        super(AlzheimerMultiTaskModel, self).__init__()\n        \n        # 3D CNN backbone for MRI images - keep original pretrained weights\n        self.cnn_backbone = r3d_18(pretrained=pretrained)\n        # Remove final classification layer\n        self.cnn_backbone.fc = nn.Identity()\n           \n        # Demographic network\n        self.demographic_net = nn.Sequential(\n            nn.Linear(8, 64), \n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n        \n        # Feature fusion layer\n        cnn_features = 512        \n        demo_features = 128  # demographics future\n        fused_features = cnn_features + demo_features\n\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(fused_features, 512),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n\n        # Multi-task heads for follow-up scores\n        self.adas11_future = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n        \n        self.adas13_future = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(), \n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n        \n        self.mmscore_future = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(), \n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n\n        # Initialize weights\n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n    \n    def forward(self, mri_image, demographics):\n        # Extract features from MRI\n        mri_features = self.cnn_backbone(mri_image)\n        \n        # Process demographic data\n        demo_features = self.demographic_net(demographics)\n        \n        fused_features = torch.cat([mri_features, demo_features], dim=1)\n        shared_features = self.fusion_layer(fused_features)\n\n        # Follow-up scores predictions\n        adas11_future = self.adas11_future(shared_features)\n        adas13_future = self.adas13_future(shared_features)\n        mmscore_future = self.mmscore_future(shared_features)\n        \n        return {\n            'adas11_future': adas11_future.squeeze(-1),\n            'adas13_future': adas13_future.squeeze(-1),\n            'mmscore_future': mmscore_future.squeeze(-1)\n        }\n\nclass AlzheimerMultiTaskLoss(nn.Module):\n    def __init__(self, uncertainty_weighting=False):\n        super(AlzheimerMultiTaskLoss, self).__init__()\n        \n        # Default equal weights for all tasks\n        self.task_weights = {\n            'adas11_future': 2.0,\n            'adas13_future': 2.0,\n            'mmscore_future': 1.0\n        }\n            \n        self.uncertainty_weighting = uncertainty_weighting\n        \n        # Learnable uncertainty parameters if using uncertainty weighting\n        if uncertainty_weighting:\n            self.log_vars = nn.Parameter(torch.zeros(3))  # 8 tasks now\n        \n        # Different loss functions for different score types\n        self.mse_loss = nn.MSELoss()\n        self.smooth_l1_loss = nn.SmoothL1Loss()\n    \n    def forward(self, predictions, targets):\n        losses = {}\n        total_loss = 0\n\n        # Follow-up scores losses with task-specific scaling\n        adas11_future_loss = self.mse_loss(predictions['adas11_future'], targets['adas11_future'])\n        adas13_future_loss = self.mse_loss(predictions['adas13_future'], targets['adas13_future'])\n        mmscore_future_loss = self.smooth_l1_loss(predictions['mmscore_future'], targets['mmscore_future'])\n        \n        task_losses = [\n            adas11_future_loss, adas13_future_loss, mmscore_future_loss\n        ]\n        task_names = [\n            'adas11_future', 'adas13_future', 'mmscore_future'\n        ]\n        \n        # Apply task weighting\n        if self.uncertainty_weighting:\n            # Uncertainty-based multi-task weighting\n            for i, (loss, name) in enumerate(zip(task_losses, task_names)):\n                precision = torch.exp(-self.log_vars[i])\n                weighted_loss = precision * loss + self.log_vars[i]\n                losses[f'{name}_loss'] = loss\n                total_loss += weighted_loss\n        else:\n            # Manual task weighting\n            for loss, name in zip(task_losses, task_names):\n                weighted_loss = self.task_weights[name] * loss\n                losses[f'{name}_loss'] = loss\n                total_loss += weighted_loss\n        \n        losses['total_loss'] = total_loss\n        return losses\n\n# Training utilities\nclass EarlyStopping:\n    def __init__(self, patience=10, min_delta=0.001):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        \n    def __call__(self, val_loss):\n        if val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n            return False\n        else:\n            self.counter += 1\n            return self.counter >= self.patience\n\n# Example usage\ndef create_alzheimer_model(pretrained=True, dropout_rate=0.3, \n                          uncertainty_weighting=True):\n    \"\"\"\n    Create Alzheimer prediction model with custom loss\n    \n    Args:\n        pretrained: Use pretrained 3D ResNet backbone\n        dropout_rate: Dropout rate for regularization\n        uncertainty_weighting: Use learnable uncertainty weighting\n    \n    Returns:\n        model, loss_fn\n    \"\"\"\n    model = AlzheimerMultiTaskModel(\n        pretrained=pretrained,\n        dropout_rate=dropout_rate\n    )\n    \n    loss_fn = AlzheimerMultiTaskLoss(\n        uncertainty_weighting=uncertainty_weighting\n    )\n    \n    return model, loss_fn","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.333725Z","iopub.execute_input":"2025-06-04T17:48:46.334127Z","iopub.status.idle":"2025-06-04T17:48:46.355232Z","shell.execute_reply.started":"2025-06-04T17:48:46.334101Z","shell.execute_reply":"2025-06-04T17:48:46.354291Z"},"id":"IIoWC5oHuWaV","papermill":{"duration":0.045603,"end_time":"2025-06-01T16:23:04.573001","exception":false,"start_time":"2025-06-01T16:23:04.527398","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Train function","metadata":{"id":"s_6jbCJ2uWaW","papermill":{"duration":0.028379,"end_time":"2025-06-01T16:23:04.630174","exception":false,"start_time":"2025-06-01T16:23:04.601795","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_alzheimer_model(model, loss_fn, train_loader, val_loader, num_epochs=200, patience = 10, \n                         learning_rate=0.001, device='cuda'):\n    \n    # Optimizer with weight decay for regularization\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, \n                           weight_decay=1e-4)\n    \n    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    #     optimizer, mode='min', patience=3, factor=0.5, verbose=True\n    # )\n    # Learning rate scheduler with warmup\n    num_warmup_steps = len(train_loader) * 5  # 5 epochs warmup\n    num_training_steps = len(train_loader) * num_epochs\n    \n    def lr_lambda(current_step):\n        if current_step < num_warmup_steps:\n            return float(current_step) / float(max(1, num_warmup_steps))\n        return max(0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps)))\n    \n    # Learning rate scheduler\n    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n    \n    # Early stopping\n    early_stopping = EarlyStopping(patience=patience, min_delta=0.002)\n    \n    best_val_loss = float('inf')\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        epoch_train_loss = 0\n        train_task_losses = {\n            'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0\n        }\n        \n        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n        for mri_batch, demo_batch, targets_batch in train_loop:\n            mri_batch = mri_batch.to(device)\n            demo_batch = demo_batch.to(device)\n            targets_batch = {k: v.to(device) for k, v in targets_batch.items()}\n            \n            optimizer.zero_grad()\n            predictions = model(mri_batch, demo_batch)\n            losses = loss_fn(predictions, targets_batch)\n            \n            losses['total_loss'].backward()\n            \n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            scheduler.step()\n            epoch_train_loss += losses['total_loss'].item()\n            \n            # Accumulate task losses\n            for task in train_task_losses.keys():\n                train_task_losses[task] += losses[f'{task}_loss'].item()\n                \n            train_loop.set_postfix({'total_loss': losses['total_loss'].item()})\n        \n        # Calculate average task losses\n        for task in train_task_losses.keys():\n            train_task_losses[task] /= len(train_loader)\n        \n        # Validation phase\n        model.eval()\n        epoch_val_loss = 0\n        val_task_losses = {\n            'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0\n        }\n        val_predictions = {\n            'adas11_future': [], 'adas13_future': [], 'mmscore_future': []\n        }\n        val_targets = {\n            'adas11_future': [], 'adas13_future': [], 'mmscore_future': []\n        }\n        \n        scaler = {\n            'adas11_future': 70, 'adas13_future': 85, 'mmscore_future': 30\n        }\n        \n        val_loop = tqdm(val_loader, desc=f\"Validation {epoch+1}/{num_epochs}\", unit=\"batch\")\n        with torch.no_grad():\n            for mri_batch, demo_batch, targets_batch in val_loop:\n                mri_batch = mri_batch.to(device)\n                demo_batch = demo_batch.to(device)\n                targets_batch = {k: v.to(device) for k, v in targets_batch.items()}\n                \n                predictions = model(mri_batch, demo_batch)\n                losses = loss_fn(predictions, targets_batch)\n                epoch_val_loss += losses['total_loss'].item()\n                \n                # Accumulate task losses\n                for task in val_task_losses.keys():\n                    val_task_losses[task] += losses[f'{task}_loss'].item()\n                \n                # Collect predictions and targets for metrics\n                for task in val_predictions.keys():\n                    val_predictions[task].extend(predictions[task].cpu().numpy())\n                    val_targets[task].extend(targets_batch[task].cpu().numpy())\n\n                val_loop.set_postfix({'total_loss': losses['total_loss'].item()})\n        # Calculate average task losses\n        for task in val_task_losses.keys():\n            val_task_losses[task] /= len(val_loader)\n        \n        # Calculate metrics\n        avg_train_loss = epoch_train_loss / len(train_loader)\n        avg_val_loss = epoch_val_loss / len(val_loader)\n        \n        # scheduler.step(avg_val_loss)\n        train_losses.append(avg_train_loss)\n        val_losses.append(avg_val_loss)\n        \n        # Calculate R² and MAE for each task\n        metrics = {}\n        for task in val_predictions.keys():\n            tar = np.array(val_targets[task])* scaler[task]\n            pre = np.array(val_predictions[task]) * scaler[task]\n            r2 = r2_score(pre, tar)\n            mae = mean_absolute_error(pre, tar)\n            metrics[f'{task}_r2'] = r2\n            metrics[f'{task}_mae'] = mae\n        \n        print(f'Epoch {epoch+1}/{num_epochs}:')\n        print(f'  Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n        print(f'  Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n        print('    🧠 ADAS11 FUTURE:')\n        print(f'    - Train Loss: {train_task_losses[\"adas11_future\"]:.4f}, Val Loss: {val_task_losses[\"adas11_future\"]:.4f}')\n        print(f'    - R²: {metrics[\"adas11_future_r2\"]:.4f}, MAE: {metrics[\"adas11_future_mae\"]:.4f}')\n        print('    🧠 ADAS13 FUTURE:')\n        print(f'    - Train Loss: {train_task_losses[\"adas13_future\"]:.4f}, Val Loss: {val_task_losses[\"adas13_future\"]:.4f}')\n        print(f'    - R²: {metrics[\"adas13_future_r2\"]:.4f}, MAE: {metrics[\"adas13_future_mae\"]:.4f}')\n        print('    🧠 MMSCORE FUTURE:')\n        print(f'    - Train Loss: {train_task_losses[\"mmscore_future\"]:.4f}, Val Loss: {val_task_losses[\"mmscore_future\"]:.4f}')\n        print(f'    - R²: {metrics[\"mmscore_future_r2\"]:.4f}, MAE: {metrics[\"mmscore_future_mae\"]:.4f}')\n        \n        # Save best model\n        if avg_val_loss < best_val_loss and avg_val_loss < avg_train_loss:\n            best_val_loss = avg_val_loss\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': best_val_loss,\n                'metrics': metrics\n            }, 'best_alzheimer_model.pth')\n            print(f'  ✅New best model saved at epoch {epoch+1} with best_val {best_val_loss:.4f}!!!')\n        # Early stopping\n        if early_stopping(avg_val_loss):\n            print(f\"‼️Early stopping at epoch {epoch+1}\")\n            break\n    \n    return train_losses, val_losses","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.356312Z","iopub.execute_input":"2025-06-04T17:48:46.356572Z","iopub.status.idle":"2025-06-04T17:48:46.382732Z","shell.execute_reply.started":"2025-06-04T17:48:46.356551Z","shell.execute_reply":"2025-06-04T17:48:46.381655Z"},"id":"V3yWYSnuuWaW","papermill":{"duration":0.047078,"end_time":"2025-06-01T16:23:04.705883","exception":false,"start_time":"2025-06-01T16:23:04.658805","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Main","metadata":{"id":"tgOfcDrduWaX","papermill":{"duration":0.028634,"end_time":"2025-06-01T16:23:04.764008","exception":false,"start_time":"2025-06-01T16:23:04.735374","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Configuration","metadata":{"id":"AUO_TG01uWaX","papermill":{"duration":0.0288,"end_time":"2025-06-01T16:23:04.821397","exception":false,"start_time":"2025-06-01T16:23:04.792597","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Configuration\nconfig = {\n    'image_folder': '/kaggle/input/fsl-brain-dataset/T1_biascorr_brain_data',\n    'train_data_csv': '/kaggle/input/brain-csv/train_6_18.csv',\n    'val_data_csv': '/kaggle/input/brain-csv/val_6_18.csv',\n    'test_data_csv': '/kaggle/input/brain-csv/test_6_18.csv',\n    'batch_size': 4,\n    'image_size': (96, 96, 96)  # Adjust based on your memory\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.384261Z","iopub.execute_input":"2025-06-04T17:48:46.384930Z","iopub.status.idle":"2025-06-04T17:48:46.403403Z","shell.execute_reply.started":"2025-06-04T17:48:46.384891Z","shell.execute_reply":"2025-06-04T17:48:46.402475Z"},"id":"DONaDcAtuWaX","papermill":{"duration":0.034147,"end_time":"2025-06-01T16:23:04.884145","exception":false,"start_time":"2025-06-01T16:23:04.849998","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.404495Z","iopub.execute_input":"2025-06-04T17:48:46.405074Z","iopub.status.idle":"2025-06-04T17:48:46.424097Z","shell.execute_reply.started":"2025-06-04T17:48:46.405031Z","shell.execute_reply":"2025-06-04T17:48:46.423133Z"},"id":"4nJQJmX4uWaY","outputId":"1ccfb8bc-5688-4488-c554-f678c25a76e4","papermill":{"duration":0.092086,"end_time":"2025-06-01T16:23:05.004969","exception":false,"start_time":"2025-06-01T16:23:04.912883","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(\"Loading data...\")\ntrain_loader, val_loader, test_loader = load_alzheimer_data(config)","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:46.425009Z","iopub.execute_input":"2025-06-04T17:48:46.425253Z","iopub.status.idle":"2025-06-04T17:48:53.595563Z","shell.execute_reply.started":"2025-06-04T17:48:46.425234Z","shell.execute_reply":"2025-06-04T17:48:53.594674Z"},"id":"P_Ov5_ewuWaY","outputId":"1b31a2ae-7dae-4cd8-fa8f-6b7008e0b383","papermill":{"duration":2.221981,"end_time":"2025-06-01T16:23:07.255891","exception":false,"start_time":"2025-06-01T16:23:05.033910","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Loading data...\nData splits - Train: 1098, Val: 122, Test: 122\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model, loss_fn = create_alzheimer_model(\n    pretrained=True,\n    uncertainty_weighting=True\n)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:53.596542Z","iopub.execute_input":"2025-06-04T17:48:53.596789Z","iopub.status.idle":"2025-06-04T17:48:57.127246Z","shell.execute_reply.started":"2025-06-04T17:48:53.596770Z","shell.execute_reply":"2025-06-04T17:48:57.126429Z"},"id":"Lw4O7BwruWaY","outputId":"8bf0688e-48e0-416b-99ff-38c3ba7f079a","papermill":{"duration":1.758671,"end_time":"2025-06-01T16:23:09.043752","exception":false,"start_time":"2025-06-01T16:23:07.285081","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/r3d_18-b3b3357e.pth\" to /root/.cache/torch/hub/checkpoints/r3d_18-b3b3357e.pth\n100%|██████████| 127M/127M [00:02<00:00, 53.0MB/s] \n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### Training","metadata":{"id":"5-jSHYYAuWaY","papermill":{"duration":0.02893,"end_time":"2025-06-01T16:23:09.102222","exception":false,"start_time":"2025-06-01T16:23:09.073292","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Train model\nprint(\"Training model...\")\ntrain_losses, val_losses = train_alzheimer_model(\n    model=model,\n    loss_fn=loss_fn,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    num_epochs=200,\n    patience=20,\n    learning_rate=1e-3,\n    device=device\n)","metadata":{"execution":{"iopub.status.busy":"2025-06-04T17:48:57.128273Z","iopub.execute_input":"2025-06-04T17:48:57.128573Z"},"id":"D9JFBV1DuWaY","outputId":"39ca408d-83fa-4a77-c43e-64499eb263c1","papermill":{"duration":22145.435502,"end_time":"2025-06-01T22:32:14.568280","exception":false,"start_time":"2025-06-01T16:23:09.132778","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Training model...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/200:   0%|          | 1/275 [01:05<4:58:21, 65.33s/batch, total_loss=0.265]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### Result","metadata":{"id":"OEdQnlQiuWaY","papermill":{"duration":0.711579,"end_time":"2025-06-01T22:32:16.170868","exception":false,"start_time":"2025-06-01T22:32:15.459289","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Update evaluation function\ndef evaluate_model(model, test_loader, device='cuda'):\n    \"\"\"Evaluate model on test set\"\"\"\n    model.eval()\n    predictions = {\n        'adas11_future': [], 'adas13_future': [], 'mmscore_future': []\n    }\n    targets = {\n        'adas11_future': [], 'adas13_future': [], 'mmscore_future': []\n    }\n    scaler = {\n        'adas11_future': 70, 'adas13_future': 85, 'mmscore_future': 30\n    }\n    \n    test_loop = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n    with torch.no_grad():\n        for mri_batch, demo_batch, targets_batch in test_loop:\n            mri_batch = mri_batch.to(device)\n            demo_batch = demo_batch.to(device)    \n            \n            preds = model(mri_batch, demo_batch)\n            \n            for task in predictions.keys():\n                predictions[task].extend(preds[task].cpu().numpy())\n                targets[task].extend(targets_batch[task].numpy())\n    \n    # Calculate final metrics\n    results = {}\n    for task in predictions.keys():\n        tar = np.array(targets[task]) * scaler[task]\n        pre = np.array(predictions[task]) * scaler[task]\n        r2 = r2_score(pre, tar)\n        mae = mean_absolute_error(pre, tar)\n        mse = mean_squared_error(pre, tar)\n        \n        results[task] = {\n            'r2_score': r2,\n            'mae': mae,\n            'mse': mse,\n            'predictions': pre,\n            'targets': tar\n        }\n    \n    return results ","metadata":{"id":"vAgeweC8uWaZ","papermill":{"duration":0.841704,"end_time":"2025-06-01T22:32:17.729474","exception":false,"start_time":"2025-06-01T22:32:16.887770","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load best model\nprint(\"Loading best model...\")\ncheckpoint = torch.load('best_alzheimer_model.pth', weights_only=False)\nmodel.load_state_dict(checkpoint['model_state_dict'])","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_iter = iter(test_loader)\nall_results = []\nfor i in range(len(test_loader)):\n    print(f\"Test {i+1}:\")\n    model.eval()\n    mri_test, demographics_test, label_test = next(test_iter)\n    mri_test = mri_test.to(device)\n    demographics_test = demographics_test.to(device)\n    # Dự đoán\n    out = model(mri_test, demographics_test)\n\n    # Scale ngược lại các giá trị\n    adas11_future_pred = (out[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n    adas11_future_actual = (label_test[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n\n    adas13_future_pred = (out[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n    adas13_future_actual = (label_test[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n\n    mmscore_future_pred = (out[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n    mmscore_future_actual = (label_test[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n\n    print('🧠ADAS11 FUTURE:')\n    print(f'🔵Predicted: {adas11_future_pred}\\n🔴Actual:    {adas11_future_actual}')\n    print('🧠ADAS13 FUTURE:')\n    print(f'🔵Predicted: {adas13_future_pred}\\n🔴Actual:    {adas13_future_actual}')\n    print('🧠MMSCORE FUTURE:')\n    print(f'🔵Predicted: {mmscore_future_pred}\\n🔴Actual:    {mmscore_future_actual}')\n    print('=============================================================================================================')\nprint(\"Done!\")\n","metadata":{"id":"makWSLV5uWaZ","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_fig(data, path):\n    import matplotlib.pyplot as plt\n    \n    test_iter = iter(data)\n    all_results = []\n    for i in range(len(data)):\n        model.eval()\n        mri_test, demographics_test, label_test = next(test_iter)\n        mri_test = mri_test.to(device)\n        demographics_test = demographics_test.to(device)\n        # Dự đoán\n        out = model(mri_test, demographics_test)\n    \n        # Scale ngược lại các giá trị\n        adas11_future_pred = (out[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n        adas11_future_actual = (label_test[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n    \n        adas13_future_pred = (out[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n        adas13_future_actual = (label_test[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n    \n        mmscore_future_pred = (out[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n        mmscore_future_actual = (label_test[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n    \n        # Gộp lại thành từng sample 1 dòng\n        batch_size = len(adas11_future_pred)\n        for j in range(batch_size):\n            all_results.append({\n                \"Test\": i + 1,\n                \"ADAS11_FUTURE_pred\": round(adas11_future_pred[j], 3),\n                \"ADAS11_FUTURE_actual\": round(adas11_future_actual[j], 3),\n                \"ADAS13_FUTURE_pred\": round(adas13_future_pred[j], 3),\n                \"ADAS13_FUTURE_actual\": round(adas13_future_actual[j], 3),\n                \"MMSCORE_FUTURE_pred\": round(mmscore_future_pred[j], 3),\n                \"MMSCORE_FUTURE_actual\": round(mmscore_future_actual[j], 3)\n            })\n    df_results = pd.DataFrame(all_results)\n    plt.figure(figsize=(20, 8))\n    # Scatter plot ADAS13\n    plt.subplot(1, 3, 1)\n    plt.scatter(df_results['ADAS11_FUTURE_actual'], df_results['ADAS11_FUTURE_pred'], alpha=0.6, color='blue', label='ADAS11 FUTURE')\n    plt.plot([0, 70], [0, 70], 'r-')\n    plt.xlabel(\"Actual\")\n    plt.ylabel(\"Predict\")\n    plt.title(\"Score\")\n    plt.tight_layout()\n    plt.legend()\n    plt.grid(True)\n    plt.subplot(1, 3, 2)\n    plt.scatter(df_results['ADAS13_FUTURE_actual'], df_results['ADAS13_FUTURE_pred'], alpha=0.6, color='blue', label='ADAS13 FUTURE')\n    plt.plot([0, 85], [0, 85], 'r-')\n    plt.xlabel(\"Actual\")\n    plt.ylabel(\"Predict\")\n    plt.title(\"Score\")\n    plt.tight_layout()\n    plt.legend()\n    plt.grid(True)\n    plt.subplot(1, 3, 3)\n    plt.scatter(df_results['MMSCORE_FUTURE_actual'], df_results['MMSCORE_FUTURE_pred'], alpha=0.6, color='blue', label='MMSCORE FUTURE')\n    plt.plot([0, 30], [0, 30], 'r-')\n    plt.xlabel(\"Actual\")\n    plt.ylabel(\"Predict\")\n    plt.title(\"Score\")\n    plt.tight_layout()\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(path, dpi=300, bbox_inches='tight')\n    # plt.show()\n    plt.close()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on test set\ndef print_test(data, type_of):\n    test_results = evaluate_model(model, data, device)\n    \n    # Print results\n    print(f\"\\n{type_of} Results:\")\n    R2_metric = {\n        'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0\n    }\n    MAE_metric = {\n        'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0\n    }\n    MSE_metric = {\n        'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0\n    }\n    for task, metrics in test_results.items():\n        R2_metric[task] = metrics['r2_score']\n        MAE_metric[task] = metrics['mae']\n        MSE_metric[task] = metrics['mse']\n    print(\"📊 Độ lệch trung bình (MAE):\")\n    print(\"🔵Tương lai\")\n    print(f\"  -ADAS11: {MAE_metric['adas11_future']:.4f} điểm\")\n    print(f\"  -ADAS13: {MAE_metric['adas13_future']:.4f} điểm\")\n    print(f\"  -MMSCORE: {MAE_metric['mmscore_future']:.4f} điểm\")\n    print(\"📊 Sai số bình phương trung bình (MSE):\")\n    print(\"🔵Tương lai\")\n    print(f\"  -ADAS11: {math.sqrt(MSE_metric['adas11_future']):.4f} điểm²\")\n    print(f\"  -ADAS13: {math.sqrt(MSE_metric['adas13_future']):.4f} điểm²\")\n    print(f\"  -MMSCORE: {math.sqrt(MSE_metric['mmscore_future']):.4f} điểm²\")\n    print(\"📊 Hệ số xác định (R² Score):\")\n    print(\"🔵Tương lai\")\n    print(f\"  -ADAS11: {R2_metric['adas11_future']:.4f} điểm\")\n    print(f\"  -ADAS13: {R2_metric['adas13_future']:.4f} điểm\")\n    print(f\"  -MMSCORE: {R2_metric['mmscore_future']:.4f} điểm\")","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Val**","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"print_test(val_loader, 'Validation')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_fig(val_loader, 'val_plot.png')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Test**","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"print_test(test_loader, 'Test')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_fig(test_loader, 'test_plot.png')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}