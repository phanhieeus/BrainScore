{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TwAoYEuuWaR"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:13:26.293776Z",
     "iopub.status.busy": "2025-06-01T16:13:26.293511Z",
     "iopub.status.idle": "2025-06-01T16:14:42.734980Z",
     "shell.execute_reply": "2025-06-01T16:14:42.734054Z",
     "shell.execute_reply.started": "2025-06-01T16:13:26.293757Z"
    },
    "id": "uR4BTOtjuWaS",
    "outputId": "ff46a852-f2c4-4bb9-c98f-500d3b68e23c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-01T16:14:52.336544Z",
     "iopub.status.busy": "2025-06-01T16:14:52.336191Z",
     "iopub.status.idle": "2025-06-01T16:14:52.341422Z",
     "shell.execute_reply": "2025-06-01T16:14:52.340682Z",
     "shell.execute_reply.started": "2025-06-01T16:14:52.336527Z"
    },
    "id": "TSOy1948uWaS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.video import r3d_18\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchio as T\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:14:52.343459Z",
     "iopub.status.busy": "2025-06-01T16:14:52.343092Z",
     "iopub.status.idle": "2025-06-01T16:14:52.367421Z",
     "shell.execute_reply": "2025-06-01T16:14:52.366858Z",
     "shell.execute_reply.started": "2025-06-01T16:14:52.343423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)                   # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)              # PyTorch GPU (1 GPU)\n",
    "    torch.cuda.manual_seed_all(seed)          # PyTorch GPU (all GPUs)\n",
    "    torch.backends.cudnn.deterministic = True # CUDNN deterministic\n",
    "    torch.backends.cudnn.benchmark = False    # Turn off speed autotune\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDuEoGA9uWaT"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:14:52.368553Z",
     "iopub.status.busy": "2025-06-01T16:14:52.368182Z",
     "iopub.status.idle": "2025-06-01T16:14:52.386053Z",
     "shell.execute_reply": "2025-06-01T16:14:52.385341Z",
     "shell.execute_reply.started": "2025-06-01T16:14:52.368537Z"
    },
    "id": "5Zbw5vR5uWaT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 image_folder,\n",
    "                 data_csv,\n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_folder: Path to folder containing image_id subfolders\n",
    "            data_csv: Path to CSV file containing all data (demographics, cognitive scores, follow-up)\n",
    "            transform: Optional transforms for MRI images\n",
    "        \"\"\"\n",
    "        \n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load CSV file\n",
    "        self.data_df = pd.read_csv(data_csv)\n",
    "        \n",
    "        # Process data\n",
    "        self.data_df = self._process_data()\n",
    "        \n",
    "        # Filter valid samples (has image file and all required data)\n",
    "        self.valid_samples = self._filter_valid_samples()\n",
    "        \n",
    "    def _process_data(self):\n",
    "        \"\"\"Process the data from CSV file\"\"\"\n",
    "        df = self.data_df.copy()\n",
    "        \n",
    "        # Convert gender to numeric\n",
    "        df['PTGENDER'] = df['PTGENDER'].astype(np.float32)\n",
    "                \n",
    "        return df\n",
    "    \n",
    "    def _filter_valid_samples(self):\n",
    "        \"\"\"Filter samples that have valid image files and complete data\"\"\"\n",
    "        valid_samples = []\n",
    "        \n",
    "        # Check if image folder exists\n",
    "        if not os.path.exists(self.image_folder):\n",
    "            return valid_samples\n",
    "        \n",
    "        for idx, row in self.data_df.iterrows():                \n",
    "            image_id = row['image_id']\n",
    "            \n",
    "            # Construct folder path with \"I\" prefix\n",
    "            folder_name = f\"I{image_id}\"\n",
    "            image_path = os.path.join(self.image_folder, folder_name)\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                continue\n",
    "            \n",
    "            # Look for the specific file name: T1_biascorr_brain.nii.gz\n",
    "            nii_file_path = os.path.join(image_path, \"T1_biascorr_brain.nii.gz\")\n",
    "            \n",
    "            if not os.path.exists(nii_file_path):\n",
    "                # If specific file doesn't exist, look for any .nii or .nii.gz file\n",
    "                if os.path.exists(image_path):\n",
    "                    files_in_folder = os.listdir(image_path)\n",
    "                    nii_files = [f for f in files_in_folder \n",
    "                                if f.endswith('.nii') or f.endswith('.nii.gz')]\n",
    "                    if len(nii_files) == 0:\n",
    "                        continue\n",
    "                    nii_file_path = os.path.join(image_path, nii_files[0])\n",
    "            \n",
    "            # Check for required data completeness\n",
    "            required_cols = [\n",
    "                'PTGENDER', 'age', 'PTEDUCAT', 'time_lapsed', 'DIAGNOSIS_now',\n",
    "                'ADAS11_future', 'ADAS13_future', 'MMSCORE_future', 'CDGLOBAL_future'\n",
    "            ]\n",
    "            missing_cols = [col for col in required_cols if col not in row or pd.isna(row[col])]\n",
    "            \n",
    "            if missing_cols:\n",
    "                continue\n",
    "            \n",
    "            # Store file path and index\n",
    "            valid_samples.append({\n",
    "                'idx': idx,\n",
    "                'image_path': nii_file_path,\n",
    "                'image_id': image_id\n",
    "            })\n",
    "        \n",
    "        return valid_samples\n",
    "    \n",
    "    def _load_mri_image(self, image_path):\n",
    "        \"\"\"Load and preprocess MRI image\"\"\"\n",
    "        # Load nii file\n",
    "        img = nib.load(image_path)\n",
    "        data = img.get_fdata()\n",
    "        \n",
    "        # Convert to float32 and add channel dimension\n",
    "        data = data.astype(np.float32)\n",
    "        \n",
    "        # Normalize intensity to [0, 1]\n",
    "        data = (data - data.min()) / (data.max() - data.min() + 1e-8)\n",
    "        \n",
    "        # Convert to tensor: (D, H, W)\n",
    "        data_tensor = torch.from_numpy(data)\n",
    "        \n",
    "        # Repeat single channel to create 3 channels: (3, D, H, W)\n",
    "        data_tensor = data_tensor.unsqueeze(0).repeat(3, 1, 1, 1)\n",
    "        \n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            data_tensor = self.transform(data_tensor)\n",
    "        \n",
    "        return data_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get sample info\n",
    "        sample_info = self.valid_samples[idx]\n",
    "        df_idx = sample_info['idx']\n",
    "        image_path = sample_info['image_path']\n",
    "        \n",
    "        # Get row data\n",
    "        row = self.data_df.iloc[df_idx]\n",
    "        \n",
    "        # Load MRI image\n",
    "        mri_image = self._load_mri_image(image_path)\n",
    "\n",
    "        # Get demographics\n",
    "        demographics = torch.tensor([\n",
    "            row['age'],\n",
    "            row['PTGENDER'],\n",
    "            row['PTEDUCAT'],\n",
    "            row['DIAGNOSIS_now'],\n",
    "            row['time_lapsed']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        # Get cognitive scores\n",
    "        scores = {\n",
    "            'ADAS11_future': row['ADAS11_future'],\n",
    "            'ADAS13_future': row['ADAS13_future'],\n",
    "            'MMSCORE_future': row['MMSCORE_future'],\n",
    "            'CDGLOBAL_future': row['CDGLOBAL_future']\n",
    "        }\n",
    "        \n",
    "        # Convert to tensors\n",
    "        targets = {\n",
    "            'adas11_future': torch.tensor(scores['ADAS11_future'], dtype=torch.float32),\n",
    "            'adas13_future': torch.tensor(scores['ADAS13_future'], dtype=torch.float32),\n",
    "            'mmscore_future': torch.tensor(scores['MMSCORE_future'], dtype=torch.float32),\n",
    "            'cdglobal_future': torch.tensor(scores['CDGLOBAL_future'], dtype=torch.float32)\n",
    "        }\n",
    "        \n",
    "        return mri_image, demographics, targets\n",
    "\n",
    "# Data loading utilities\n",
    "def create_data_transforms(train=True, image_size=(64, 64, 64)):\n",
    "    \"\"\"Create transforms for MRI data\"\"\"\n",
    "    \n",
    "    if train:\n",
    "        transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            T.RandomFlip(axes=('LR',), p=0.5),\n",
    "            T.RandomAffine(scales=0.1, degrees=10, translation=5, p=0.75),\n",
    "            T.RandomNoise(std=0.01, p=0.5),\n",
    "            T.RandomMotion(p=0.3),\n",
    "            # T.ZNormalization()\n",
    "        ])\n",
    "    else:\n",
    "        transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            # T.ZNormalization()\n",
    "        ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:14:52.387175Z",
     "iopub.status.busy": "2025-06-01T16:14:52.386899Z",
     "iopub.status.idle": "2025-06-01T16:14:52.401743Z",
     "shell.execute_reply": "2025-06-01T16:14:52.401205Z",
     "shell.execute_reply.started": "2025-06-01T16:14:52.387152Z"
    },
    "id": "vfu-WLstuWaU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(image_folder,\n",
    "                       data_csv,\n",
    "                       batch_size=8,\n",
    "                       val_split=0.1,\n",
    "                       test_split=0.1,\n",
    "                       image_size=(64, 64, 64)):\n",
    "    \"\"\"\n",
    "    Create train, validation, and test data loaders\n",
    "\n",
    "    Args:\n",
    "        image_folder: Path to MRI images folder\n",
    "        data_csv: Path to CSV file containing all data\n",
    "        batch_size: Batch size for training\n",
    "        val_split: Validation split ratio\n",
    "        test_split: Test split ratio\n",
    "        image_size: Target size for MRI images\n",
    "\n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "\n",
    "    # Create full dataset\n",
    "    full_dataset = AlzheimerDataset(\n",
    "        image_folder=image_folder,\n",
    "        data_csv=data_csv,\n",
    "        transform=None  # Will be set later\n",
    "    )\n",
    "\n",
    "    # Calculate split sizes\n",
    "    dataset_size = len(full_dataset)\n",
    "    test_size = int(dataset_size * test_split)\n",
    "    val_size = int(dataset_size * val_split)\n",
    "    train_size = dataset_size - val_size - test_size\n",
    "\n",
    "    # Random split\n",
    "    train_indices, val_indices, test_indices = torch.utils.data.random_split(\n",
    "        range(dataset_size), [train_size, val_size, test_size]\n",
    "    )\n",
    "\n",
    "    # Create transforms\n",
    "    train_transform = create_data_transforms(train=True, image_size=image_size)\n",
    "    val_test_transform = create_data_transforms(train=False, image_size=image_size)\n",
    "\n",
    "    # Create subset datasets\n",
    "    train_dataset = torch.utils.data.Subset(full_dataset, train_indices.indices)\n",
    "    val_dataset = torch.utils.data.Subset(full_dataset, val_indices.indices)\n",
    "    test_dataset = torch.utils.data.Subset(full_dataset, test_indices.indices)\n",
    "\n",
    "    # Apply transforms\n",
    "    full_dataset.transform = train_transform\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"Data splits - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Example usage\n",
    "def load_alzheimer_data(config):\n",
    "    \"\"\"\n",
    "    Load Alzheimer dataset with given configuration\n",
    "\n",
    "    config should contain:\n",
    "    - image_folder: path to images\n",
    "    - data_csv: path to data file\n",
    "    - batch_size: batch size\n",
    "    - image_size: tuple of target image dimensions\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        image_folder=config['image_folder'],\n",
    "        data_csv=config['data_csv'],\n",
    "        batch_size=config.get('batch_size', 8),\n",
    "        image_size=config.get('image_size', (64, 64, 64)),\n",
    "        val_split=config.get('val_split', 0.1),\n",
    "        test_split=config.get('test_split', 0.1)\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc85rznRuWaV"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T15:48:30.164806Z",
     "iopub.status.busy": "2025-06-01T15:48:30.164488Z",
     "iopub.status.idle": "2025-06-01T15:48:30.178946Z",
     "shell.execute_reply": "2025-06-01T15:48:30.178375Z",
     "shell.execute_reply.started": "2025-06-01T15:48:30.164784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # 3D CNN backbone for MRI images - keep original pretrained weights\n",
    "# cnn_backbone = r3d_18(pretrained=True)\n",
    "# # Remove final classification layer\n",
    "# cnn_backbone.fc = nn.Identity()\n",
    "# for param in cnn_backbone.parameters():\n",
    "#     print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:14:52.402807Z",
     "iopub.status.busy": "2025-06-01T16:14:52.402497Z",
     "iopub.status.idle": "2025-06-01T16:14:52.420141Z",
     "shell.execute_reply": "2025-06-01T16:14:52.419565Z",
     "shell.execute_reply.started": "2025-06-01T16:14:52.402784Z"
    },
    "id": "IIoWC5oHuWaV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AlzheimerMultiTaskModel(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.3):\n",
    "        super(AlzheimerMultiTaskModel, self).__init__()\n",
    "        \n",
    "        # 3D CNN backbone for MRI images - keep original pretrained weights\n",
    "        self.cnn_backbone = r3d_18(pretrained=pretrained)\n",
    "        # Remove final classification layer\n",
    "        self.cnn_backbone.fc = nn.Identity()\n",
    "           \n",
    "        # Demographic network\n",
    "        self.demographic_net = nn.Sequential(\n",
    "            nn.Linear(5, 64),  # gender(1) + age(1) + education(1) + diagnosis(1) + time_future(1)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Feature fusion layer\n",
    "        cnn_features = 512        \n",
    "        demo_features = 128  # demographics future\n",
    "        fused_features = cnn_features + demo_features\n",
    "\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(fused_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Multi-task heads for follow-up scores\n",
    "        self.adas11_future = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.adas13_future = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.mmscore_future = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.cdglobal_future = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, mri_image, demographics):\n",
    "        # Extract features from MRI\n",
    "        mri_features = self.cnn_backbone(mri_image)\n",
    "        \n",
    "        # Process demographic data\n",
    "        demo_features = self.demographic_net(demographics)\n",
    "        \n",
    "        fused_features = torch.cat([mri_features, demo_features], dim=1)\n",
    "        shared_features = self.fusion_layer(fused_features)\n",
    "\n",
    "        # Follow-up scores predictions\n",
    "        adas11_future = self.adas11_future(shared_features)\n",
    "        adas13_future = self.adas13_future(shared_features)\n",
    "        mmscore_future = self.mmscore_future(shared_features)\n",
    "        cdglobal_future = self.cdglobal_future(shared_features)\n",
    "        \n",
    "        return {\n",
    "            'adas11_future': adas11_future.squeeze(-1),\n",
    "            'adas13_future': adas13_future.squeeze(-1),\n",
    "            'mmscore_future': mmscore_future.squeeze(-1),\n",
    "            'cdglobal_future': cdglobal_future.squeeze(-1)\n",
    "        }\n",
    "\n",
    "class AlzheimerMultiTaskLoss(nn.Module):\n",
    "    def __init__(self, uncertainty_weighting=False):\n",
    "        super(AlzheimerMultiTaskLoss, self).__init__()\n",
    "        \n",
    "        # Default equal weights for all tasks\n",
    "        self.task_weights = {\n",
    "            'adas11_future': 3.0,\n",
    "            'adas13_future': 3.0,\n",
    "            'mmscore_future': 2.0,\n",
    "            'cdglobal_future': 1.0\n",
    "        }\n",
    "            \n",
    "        self.uncertainty_weighting = uncertainty_weighting\n",
    "        \n",
    "        # Learnable uncertainty parameters if using uncertainty weighting\n",
    "        if uncertainty_weighting:\n",
    "            self.log_vars = nn.Parameter(torch.zeros(8))  # 8 tasks now\n",
    "        \n",
    "        # Different loss functions for different score types\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.smooth_l1_loss = nn.SmoothL1Loss()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        losses = {}\n",
    "        total_loss = 0\n",
    "\n",
    "        # Follow-up scores losses with task-specific scaling\n",
    "        adas11_future_loss = self.mse_loss(predictions['adas11_future'], targets['adas11_future'])\n",
    "        adas13_future_loss = self.mse_loss(predictions['adas13_future'], targets['adas13_future'])\n",
    "        mmscore_future_loss = self.smooth_l1_loss(predictions['mmscore_future'], targets['mmscore_future'])\n",
    "        cdglobal_future_loss = self.smooth_l1_loss(predictions['cdglobal_future'], targets['cdglobal_future'])\n",
    "        \n",
    "        task_losses = [\n",
    "            adas11_future_loss, adas13_future_loss, mmscore_future_loss, cdglobal_future_loss\n",
    "        ]\n",
    "        task_names = [\n",
    "            'adas11_future', 'adas13_future', 'mmscore_future', 'cdglobal_future'\n",
    "        ]\n",
    "        \n",
    "        # Apply task weighting\n",
    "        if self.uncertainty_weighting:\n",
    "            # Uncertainty-based multi-task weighting\n",
    "            for i, (loss, name) in enumerate(zip(task_losses, task_names)):\n",
    "                precision = torch.exp(-self.log_vars[i])\n",
    "                weighted_loss = precision * loss + self.log_vars[i]\n",
    "                losses[f'{name}_loss'] = loss\n",
    "                total_loss += weighted_loss\n",
    "        else:\n",
    "            # Manual task weighting\n",
    "            for loss, name in zip(task_losses, task_names):\n",
    "                weighted_loss = self.task_weights[name] * loss\n",
    "                losses[f'{name}_loss'] = loss\n",
    "                total_loss += weighted_loss\n",
    "        \n",
    "        losses['total_loss'] = total_loss\n",
    "        return losses\n",
    "\n",
    "# Training utilities\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "# Example usage\n",
    "def create_alzheimer_model(pretrained=True, dropout_rate=0.3, \n",
    "                          uncertainty_weighting=True):\n",
    "    \"\"\"\n",
    "    Create Alzheimer prediction model with custom loss\n",
    "    \n",
    "    Args:\n",
    "        pretrained: Use pretrained 3D ResNet backbone\n",
    "        dropout_rate: Dropout rate for regularization\n",
    "        uncertainty_weighting: Use learnable uncertainty weighting\n",
    "    \n",
    "    Returns:\n",
    "        model, loss_fn\n",
    "    \"\"\"\n",
    "    model = AlzheimerMultiTaskModel(\n",
    "        pretrained=pretrained,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    \n",
    "    loss_fn = AlzheimerMultiTaskLoss(\n",
    "        uncertainty_weighting=uncertainty_weighting\n",
    "    )\n",
    "    \n",
    "    return model, loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_6jbCJ2uWaW"
   },
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:16:24.309001Z",
     "iopub.status.busy": "2025-06-01T16:16:24.308454Z",
     "iopub.status.idle": "2025-06-01T16:16:24.325569Z",
     "shell.execute_reply": "2025-06-01T16:16:24.324820Z",
     "shell.execute_reply.started": "2025-06-01T16:16:24.308980Z"
    },
    "id": "V3yWYSnuuWaW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_alzheimer_model(model, train_loader, val_loader, num_epochs=200, patience = 10, \n",
    "                         learning_rate=0.001, device='cuda'):\n",
    "    \"\"\"\n",
    "    Training function for Alzheimer prediction model\n",
    "    \"\"\"\n",
    "    model, loss_fn = create_alzheimer_model(\n",
    "            pretrained=True,          \n",
    "        uncertainty_weighting=True\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Optimizer with weight decay for regularization\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, \n",
    "                           weight_decay=1e-4)\n",
    "    \n",
    "    # Learning rate scheduler with warmup\n",
    "    num_warmup_steps = len(train_loader) * 5  # 5 epochs warmup\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    \n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps)))\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=0.001)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        train_task_losses = {\n",
    "            'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0, 'cdglobal_future': 0\n",
    "        }\n",
    "        \n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for mri_batch, demo_batch, targets_batch in train_loop:\n",
    "            mri_batch = mri_batch.to(device)\n",
    "            demo_batch = demo_batch.to(device)\n",
    "            targets_batch = {k: v.to(device) for k, v in targets_batch.items()}\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(mri_batch, demo_batch)\n",
    "            losses = loss_fn(predictions, targets_batch)\n",
    "            \n",
    "            losses['total_loss'].backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_train_loss += losses['total_loss'].item()\n",
    "            \n",
    "            # Accumulate task losses\n",
    "            for task in train_task_losses.keys():\n",
    "                train_task_losses[task] += losses[f'{task}_loss'].item()\n",
    "                \n",
    "            train_loop.set_postfix({'total_loss': losses['total_loss'].item()})\n",
    "        \n",
    "        # Calculate average task losses\n",
    "        for task in train_task_losses.keys():\n",
    "            train_task_losses[task] /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        val_task_losses = {\n",
    "            'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0, 'cdglobal_future': 0\n",
    "        }\n",
    "        val_predictions = {\n",
    "            'adas11_future': [], 'adas13_future': [], 'mmscore_future': [], 'cdglobal_future': []\n",
    "        }\n",
    "        val_targets = {\n",
    "            'adas11_future': [], 'adas13_future': [], 'mmscore_future': [], 'cdglobal_future': []\n",
    "        }\n",
    "        \n",
    "        scaler = {\n",
    "            'adas11_future': 70, 'adas13_future': 85, 'mmscore_future': 30, 'cdglobal_future': 3\n",
    "        }\n",
    "        \n",
    "        val_loop = tqdm(val_loader, desc=f\"Validation {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        with torch.no_grad():\n",
    "            for mri_batch, demo_batch, targets_batch in val_loop:\n",
    "                mri_batch = mri_batch.to(device)\n",
    "                demo_batch = demo_batch.to(device)\n",
    "                targets_batch = {k: v.to(device) for k, v in targets_batch.items()}\n",
    "                \n",
    "                predictions = model(mri_batch, demo_batch)\n",
    "                losses = loss_fn(predictions, targets_batch)\n",
    "                epoch_val_loss += losses['total_loss'].item()\n",
    "                \n",
    "                # Accumulate task losses\n",
    "                for task in val_task_losses.keys():\n",
    "                    val_task_losses[task] += losses[f'{task}_loss'].item()\n",
    "                \n",
    "                # Collect predictions and targets for metrics\n",
    "                for task in val_predictions.keys():\n",
    "                    val_predictions[task].extend(predictions[task].cpu().numpy())\n",
    "                    val_targets[task].extend(targets_batch[task].cpu().numpy())\n",
    "\n",
    "                val_loop.set_postfix({'total_loss': losses['total_loss'].item()})\n",
    "        # Calculate average task losses\n",
    "        for task in val_task_losses.keys():\n",
    "            val_task_losses[task] /= len(val_loader)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Calculate R² and MAE for each task\n",
    "        metrics = {}\n",
    "        for task in val_predictions.keys():\n",
    "            tar = np.array(val_targets[task])* scaler[task]\n",
    "            pre = np.array(val_predictions[task]) * scaler[task]\n",
    "            r2 = r2_score(pre, tar)\n",
    "            mae = mean_absolute_error(pre, tar)\n",
    "            metrics[f'{task}_r2'] = r2\n",
    "            metrics[f'{task}_mae'] = mae\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        print(f'  Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('    🧠 ADAS11 FUTURE:')\n",
    "        print(f'    - Train Loss: {train_task_losses[\"adas11_future\"]:.4f}, Val Loss: {val_task_losses[\"adas11_future\"]:.4f}')\n",
    "        print(f'    - R²: {metrics[\"adas11_future_r2\"]:.4f}, MAE: {metrics[\"adas11_future_mae\"]:.4f}')\n",
    "        print('    🧠 ADAS13 FUTURE:')\n",
    "        print(f'    - Train Loss: {train_task_losses[\"adas13_future\"]:.4f}, Val Loss: {val_task_losses[\"adas13_future\"]:.4f}')\n",
    "        print(f'    - R²: {metrics[\"adas13_future_r2\"]:.4f}, MAE: {metrics[\"adas13_future_mae\"]:.4f}')\n",
    "        print('    🧠 MMSCORE FUTURE:')\n",
    "        print(f'    - Train Loss: {train_task_losses[\"mmscore_future\"]:.4f}, Val Loss: {val_task_losses[\"mmscore_future\"]:.4f}')\n",
    "        print(f'    - R²: {metrics[\"mmscore_future_r2\"]:.4f}, MAE: {metrics[\"mmscore_future_mae\"]:.4f}')\n",
    "        print('    🧠 CDGLOBAL FUTURE:')\n",
    "        print(f'    - Train Loss: {train_task_losses[\"cdglobal_future\"]:.4f}, Val Loss: {val_task_losses[\"cdglobal_future\"]:.4f}')\n",
    "        print(f'    - R²: {metrics[\"cdglobal_future_r2\"]:.4f}, MAE: {metrics[\"cdglobal_future_mae\"]:.4f}')\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss and avg_val_loss < avg_train_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "                'metrics': metrics\n",
    "            }, 'best_alzheimer_model.pth')\n",
    "            print(f'  ✅New best model saved at epoch {epoch+1} with best_val {best_val_loss:.4f}!!!')\n",
    "        # Early stopping\n",
    "        if early_stopping(avg_val_loss):\n",
    "            print(f\"‼️Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgOfcDrduWaX"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUO_TG01uWaX"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:17:54.533770Z",
     "iopub.status.busy": "2025-06-01T16:17:54.533530Z",
     "iopub.status.idle": "2025-06-01T16:17:54.537739Z",
     "shell.execute_reply": "2025-06-01T16:17:54.536950Z",
     "shell.execute_reply.started": "2025-06-01T16:17:54.533755Z"
    },
    "id": "DONaDcAtuWaX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'image_folder': '/kaggle/input/fsl-brain-dataset/skull_stripped/skull_stripped/T1_biascorr_brain_data',\n",
    "    'data_csv': '/kaggle/input/csv-new-data/new_data.csv',\n",
    "    'batch_size': 4,\n",
    "    'image_size': (96, 96, 96),  # Adjust based on your memory\n",
    "    'val_split': 0.1,\n",
    "    'test_split':0.02\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:14:52.457838Z",
     "iopub.status.busy": "2025-06-01T16:14:52.457578Z",
     "iopub.status.idle": "2025-06-01T16:14:52.518614Z",
     "shell.execute_reply": "2025-06-01T16:14:52.517852Z",
     "shell.execute_reply.started": "2025-06-01T16:14:52.457824Z"
    },
    "id": "4nJQJmX4uWaY",
    "outputId": "1ccfb8bc-5688-4488-c554-f678c25a76e4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:17:57.949759Z",
     "iopub.status.busy": "2025-06-01T16:17:57.949196Z",
     "iopub.status.idle": "2025-06-01T16:17:58.419666Z",
     "shell.execute_reply": "2025-06-01T16:17:58.418769Z",
     "shell.execute_reply.started": "2025-06-01T16:17:57.949737Z"
    },
    "id": "P_Ov5_ewuWaY",
    "outputId": "1b31a2ae-7dae-4cd8-fa8f-6b7008e0b383",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "train_loader, val_loader, test_loader = load_alzheimer_data(config)\n",
    "# print(f\"Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:18:11.554604Z",
     "iopub.status.busy": "2025-06-01T16:18:11.553823Z",
     "iopub.status.idle": "2025-06-01T16:18:13.634082Z",
     "shell.execute_reply": "2025-06-01T16:18:13.633521Z",
     "shell.execute_reply.started": "2025-06-01T16:18:11.554579Z"
    },
    "id": "Lw4O7BwruWaY",
    "outputId": "8bf0688e-48e0-416b-99ff-38c3ba7f079a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, loss_fn = create_alzheimer_model(\n",
    "    pretrained=True,\n",
    "    uncertainty_weighting=True\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-jSHYYAuWaY"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:18:19.993930Z",
     "iopub.status.busy": "2025-06-01T16:18:19.993271Z",
     "iopub.status.idle": "2025-06-01T16:18:34.296439Z",
     "shell.execute_reply": "2025-06-01T16:18:34.295411Z",
     "shell.execute_reply.started": "2025-06-01T16:18:19.993905Z"
    },
    "id": "D9JFBV1DuWaY",
    "outputId": "39ca408d-83fa-4a77-c43e-64499eb263c1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "train_losses, val_losses = train_alzheimer_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=200,\n",
    "    patience=20,\n",
    "    learning_rate=1e-4,\n",
    "    # learning_rate=0.001,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEdQnlQiuWaY"
   },
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T15:48:34.372352Z",
     "iopub.status.busy": "2025-06-01T15:48:34.371982Z",
     "iopub.status.idle": "2025-06-01T15:48:34.379203Z",
     "shell.execute_reply": "2025-06-01T15:48:34.378498Z",
     "shell.execute_reply.started": "2025-06-01T15:48:34.372327Z"
    },
    "id": "vAgeweC8uWaZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Update evaluation function\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    predictions = {\n",
    "        'adas11_future': [], 'adas13_future': [], 'mmscore_future': [], 'cdglobal_future': []\n",
    "    }\n",
    "    targets = {\n",
    "        'adas11_future': [], 'adas13_future': [], 'mmscore_future': [], 'cdglobal_future': []\n",
    "    }\n",
    "    scaler = {\n",
    "        'adas11_future': 70, 'adas13_future': 85, 'mmscore_future': 30, 'cdglobal_future': 3\n",
    "    }\n",
    "    \n",
    "    test_loop = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for mri_batch, demo_batch, targets_batch in test_loop:\n",
    "            mri_batch = mri_batch.to(device)\n",
    "            demo_batch = demo_batch.to(device)    \n",
    "            \n",
    "            preds = model(mri_batch, demo_batch)\n",
    "            \n",
    "            for task in predictions.keys():\n",
    "                predictions[task].extend(preds[task].cpu().numpy())\n",
    "                targets[task].extend(targets_batch[task].numpy())\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    results = {}\n",
    "    for task in predictions.keys():\n",
    "        tar = np.array(targets[task]) * scaler[task]\n",
    "        pre = np.array(predictions[task]) * scaler[task]\n",
    "        r2 = r2_score(pre, tar)\n",
    "        mae = mean_absolute_error(pre, tar)\n",
    "        mse = mean_squared_error(pre, tar)\n",
    "        \n",
    "        results[task] = {\n",
    "            'r2_score': r2,\n",
    "            'mae': mae,\n",
    "            'mse': mse,\n",
    "            'predictions': pre,\n",
    "            'targets': tar\n",
    "        }\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T15:48:34.380003Z",
     "iopub.status.busy": "2025-06-01T15:48:34.379834Z",
     "iopub.status.idle": "2025-06-01T15:48:36.999371Z",
     "shell.execute_reply": "2025-06-01T15:48:36.998779Z",
     "shell.execute_reply.started": "2025-06-01T15:48:34.379990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "print(\"Loading best model...\")\n",
    "checkpoint = torch.load('/kaggle/input/brain_model/pytorch/default/4/best_alzheimer_model.pth', weights_only=False, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T06:42:32.765779Z",
     "iopub.status.busy": "2025-05-31T06:42:32.765508Z",
     "iopub.status.idle": "2025-05-31T06:42:33.195518Z",
     "shell.execute_reply": "2025-05-31T06:42:33.194966Z",
     "shell.execute_reply.started": "2025-05-31T06:42:32.765762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Load best model\n",
    "# print(\"Loading best model...\")\n",
    "# checkpoint = torch.load('best_alzheimer_model.pth', weights_only=False)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T15:49:10.939684Z",
     "iopub.status.busy": "2025-06-01T15:49:10.939059Z",
     "iopub.status.idle": "2025-06-01T15:49:39.245178Z",
     "shell.execute_reply": "2025-06-01T15:49:39.244265Z",
     "shell.execute_reply.started": "2025-06-01T15:49:10.939656Z"
    },
    "id": "makWSLV5uWaZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)\n",
    "all_results = []\n",
    "for i in range(len(test_loader)):\n",
    "    print(f\"Test {i+1}:\")\n",
    "    model.eval()\n",
    "    mri_test, demographics_test, label_test = next(test_iter)\n",
    "    mri_test = mri_test.to(device)\n",
    "    demographics_test = demographics_test.to(device)\n",
    "    # Dự đoán\n",
    "    out = model(mri_test, demographics_test)\n",
    "\n",
    "    # Scale ngược lại các giá trị\n",
    "    adas11_future_pred = (out[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n",
    "    adas11_future_actual = (label_test[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n",
    "\n",
    "    adas13_future_pred = (out[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n",
    "    adas13_future_actual = (label_test[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n",
    "\n",
    "    mmscore_future_pred = (out[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n",
    "    mmscore_future_actual = (label_test[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n",
    "\n",
    "    cdglobal_future_pred = (out[\"cdglobal_future\"] * 3).cpu().detach().numpy().tolist()\n",
    "    cdglobal_future_actual = (label_test[\"cdglobal_future\"] * 3).cpu().detach().numpy().tolist()\n",
    "\n",
    "    print('🧠ADAS11 FUTURE:')\n",
    "    print(f'🔵Predicted: {adas11_future_pred}\\n🔴Actual:    {adas11_future_actual}')\n",
    "    print('🧠ADAS13 FUTURE:')\n",
    "    print(f'🔵Predicted: {adas13_future_pred}\\n🔴Actual:    {adas13_future_actual}')\n",
    "    print('🧠MMSCORE FUTURE:')\n",
    "    print(f'🔵Predicted: {mmscore_future_pred}\\n🔴Actual:    {mmscore_future_actual}')\n",
    "    print('🧠CDGLOBAL FUTURE:')\n",
    "    print(f'🔵Predicted: {cdglobal_future_pred}\\n🔴Actual:    {cdglobal_future_actual}')\n",
    "    print('=============================================================================================================')\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_fig(data, path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    test_iter = iter(data)\n",
    "    all_results = []\n",
    "    for i in range(len(data)):\n",
    "        model.eval()\n",
    "        mri_test, demographics_test, label_test = next(test_iter)\n",
    "        mri_test = mri_test.to(device)\n",
    "        demographics_test = demographics_test.to(device)\n",
    "        # Dự đoán\n",
    "        out = model(mri_test, demographics_test)\n",
    "    \n",
    "        # Scale ngược lại các giá trị\n",
    "        adas11_future_pred = (out[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n",
    "        adas11_future_actual = (label_test[\"adas11_future\"] * 70).cpu().detach().numpy().tolist()\n",
    "    \n",
    "        adas13_future_pred = (out[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n",
    "        adas13_future_actual = (label_test[\"adas13_future\"] * 85).cpu().detach().numpy().tolist()\n",
    "    \n",
    "        mmscore_future_pred = (out[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n",
    "        mmscore_future_actual = (label_test[\"mmscore_future\"] * 30).cpu().detach().numpy().tolist()\n",
    "    \n",
    "        cdglobal_future_pred = (out[\"cdglobal_future\"] * 3).cpu().detach().numpy().tolist()\n",
    "        cdglobal_future_actual = (label_test[\"cdglobal_future\"] * 3).cpu().detach().numpy().tolist()\n",
    "    \n",
    "        # Gộp lại thành từng sample 1 dòng\n",
    "        batch_size = len(cdglobal_future_pred)\n",
    "        for j in range(batch_size):\n",
    "            all_results.append({\n",
    "                \"Test\": i + 1,\n",
    "                \"ADAS11_FUTURE_pred\": round(adas11_future_pred[j], 3),\n",
    "                \"ADAS11_FUTURE_actual\": round(adas11_future_actual[j], 3),\n",
    "                \"ADAS13_FUTURE_pred\": round(adas13_future_pred[j], 3),\n",
    "                \"ADAS13_FUTURE_actual\": round(adas13_future_actual[j], 3),\n",
    "                \"MMSCORE_FUTURE_pred\": round(mmscore_future_pred[j], 3),\n",
    "                \"MMSCORE_FUTURE_actual\": round(mmscore_future_actual[j], 3),\n",
    "                \"CDGLOBAL_FUTURE_pred\": round(cdglobal_future_pred[j], 3),\n",
    "                \"CDGLOBAL_FUTURE_actual\": round(cdglobal_future_actual[j], 3)\n",
    "            })\n",
    "    df_results = pd.DataFrame(all_results)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    # Scatter plot ADAS13\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(df_results['ADAS11_FUTURE_actual'], df_results['ADAS11_FUTURE_pred'], alpha=0.6, color='blue', label='ADAS11 FUTURE')\n",
    "    plt.plot([0, 70], [0, 70], 'r-')  # Đường chéo y = x để so sánh\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predict\")\n",
    "    plt.title(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter(df_results['ADAS13_FUTURE_actual'], df_results['ADAS13_FUTURE_pred'], alpha=0.6, color='blue', label='ADAS13 FUTURE')\n",
    "    plt.plot([0, 85], [0, 85], 'r-')  # Đường chéo y = x để so sánh\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predict\")\n",
    "    plt.title(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.scatter(df_results['MMSCORE_FUTURE_actual'], df_results['MMSCORE_FUTURE_pred'], alpha=0.6, color='blue', label='MMSCORE FUTURE')\n",
    "    plt.plot([-2, 30], [-2, 30], 'r-')  # Đường chéo y = x để so sánh\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predict\")\n",
    "    plt.title(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(df_results['CDGLOBAL_FUTURE_actual'], df_results['CDGLOBAL_FUTURE_pred'], alpha=0.6, color='blue', label='CDGLOBAL FUTURE')\n",
    "    plt.plot([0, 3], [0, 3], 'r-')  # Đường chéo y = x để so sánh\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predict\")\n",
    "    plt.title(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "def print_test(data):\n",
    "    print(\"Evaluating...\")\n",
    "    test_results = evaluate_model(model, data, device)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nTest Results:\")\n",
    "    R2_metric = {\n",
    "        'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0, 'cdglobal_future': 0\n",
    "    }\n",
    "    MAE_metric = {\n",
    "        'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0, 'cdglobal_future': 0\n",
    "    }\n",
    "    MSE_metric = {\n",
    "        'adas11_future': 0, 'adas13_future': 0, 'mmscore_future': 0, 'cdglobal_future': 0\n",
    "    }\n",
    "    for task, metrics in test_results.items():\n",
    "        # print(f\"{task}:\")\n",
    "        # print(f\"  R² Score: {metrics['r2_score']:.4f}\")\n",
    "        # print(f\"  MAE: {metrics['mae']:.4f}\")\n",
    "        # print(f\"  MSE: {metrics['mse']:.4f}\")\n",
    "        R2_metric[task] = metrics['r2_score']\n",
    "        MAE_metric[task] = metrics['mae']\n",
    "        MSE_metric[task] = metrics['mse']\n",
    "    print(\"📊 Độ lệch trung bình (MAE):\")\n",
    "    print(\"🔵Tương lai\")\n",
    "    print(f\"  -ADAS11: {MAE_metric['adas11_future']:.4f} điểm\")\n",
    "    print(f\"  -ADAS13: {MAE_metric['adas13_future']:.4f} điểm\")\n",
    "    print(f\"  -MMSCORE: {MAE_metric['mmscore_future']:.4f} điểm\")\n",
    "    print(f\"  -CDGLOBAL: {MAE_metric['cdglobal_future']:.4f} điểm\")\n",
    "    print(\"📊 Sai số bình phương trung bình (MSE):\")\n",
    "    print(\"🔵Tương lai\")\n",
    "    print(f\"  -ADAS11: {math.sqrt(MSE_metric['adas11_future']):.4f} điểm²\")\n",
    "    print(f\"  -ADAS13: {math.sqrt(MSE_metric['adas13_future']):.4f} điểm²\")\n",
    "    print(f\"  -MMSCORE: {math.sqrt(MSE_metric['mmscore_future']):.4f} điểm²\")\n",
    "    print(f\"  -CDGLOBAL: {math.sqrt(MSE_metric['cdglobal_future']):.4f} điểm²\")\n",
    "    print(\"📊 Hệ số xác định (R² Score):\")\n",
    "    print(\"🔵Tương lai\")\n",
    "    print(f\"  -ADAS11: {R2_metric['adas11_future']:.4f} điểm\")\n",
    "    print(f\"  -ADAS13: {R2_metric['adas13_future']:.4f} điểm\")\n",
    "    print(f\"  -MMSCORE: {R2_metric['mmscore_future']:.4f} điểm\")\n",
    "    print(f\"  -CDGLOBAL: {R2_metric['cdglobal_future']:.4f} điểm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print_test(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_fig(train_loader, 'train_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print_test(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_fig(val_loader, 'val_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print_test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_fig(test_loader, 'test_plot.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7317087,
     "sourceId": 11920627,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7557251,
     "sourceId": 12027700,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03d2769fde4b47e380d973cdf9e80a70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05ee0761ff194b5d831ee382a1e1d0a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb64504d4e1649de933d7a88bf2f5509",
      "placeholder": "​",
      "style": "IPY_MODEL_ab129bcdaa2f47aaa96ad17e36cb0f14",
      "value": "\n<b>Thank You</b></center>"
     }
    },
    "12abe82837de4bd9bb3bf080939b493a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19a0915dab2e41b9bfeb4f4f00623eea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d7bc82ebac4451f9fa155d528c2250a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2474a29c59044abda97fa0fafa54fd80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "262356e006ae43c7b733431fde17ef15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ec4b4fb4e064afd9eaf2ba291120e11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b695b361a4b34b87a25835b5af9b0586",
      "placeholder": "​",
      "style": "IPY_MODEL_03d2769fde4b47e380d973cdf9e80a70",
      "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
     }
    },
    "349d53a77e244ec088701bcfc99cc18b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d7bc82ebac4451f9fa155d528c2250a",
      "placeholder": "​",
      "style": "IPY_MODEL_262356e006ae43c7b733431fde17ef15",
      "value": "Kaggle credentials successfully validated."
     }
    },
    "5015410ed96348b39e6a5b79cae07d25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "7e8d8c570f7a4e33bf3351af4137cafb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Username:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_2474a29c59044abda97fa0fafa54fd80",
      "placeholder": "​",
      "style": "IPY_MODEL_d87a46fc65214f5aae742a428002b2b3",
      "value": "ttn2807"
     }
    },
    "86b707412de54ffa85f69c78d7480571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_349d53a77e244ec088701bcfc99cc18b"
      ],
      "layout": "IPY_MODEL_5015410ed96348b39e6a5b79cae07d25"
     }
    },
    "a5c85673c8f547988844ab2fa8e4cc25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab129bcdaa2f47aaa96ad17e36cb0f14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac81cc5e40a84f66bdb5afb9daaa21a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_ed49021b9f8447a5b2af63c731cb600c",
      "placeholder": "​",
      "style": "IPY_MODEL_ccc1ea51b32a404583e408efebe68539",
      "value": ""
     }
    },
    "b695b361a4b34b87a25835b5af9b0586": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb64504d4e1649de933d7a88bf2f5509": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3aa2c7bf6fe441991e444bd0ad284d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19a0915dab2e41b9bfeb4f4f00623eea",
      "placeholder": "​",
      "style": "IPY_MODEL_12abe82837de4bd9bb3bf080939b493a",
      "value": "Connecting..."
     }
    },
    "ccc1ea51b32a404583e408efebe68539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d87a46fc65214f5aae742a428002b2b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db9b739f1ee0408b89e92a2b42ac4420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "e3e5600c5d914fae93a2cb69462dd028": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_a5c85673c8f547988844ab2fa8e4cc25",
      "style": "IPY_MODEL_db9b739f1ee0408b89e92a2b42ac4420",
      "tooltip": ""
     }
    },
    "ed49021b9f8447a5b2af63c731cb600c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
